```{r}
# Minneapolis.Rmd: This file contains the code used for importing, cleaning, and preparing the public data
# for this city. The output of this file is the dataset used for modeling in the Lasso_RandomFores.Rmd script.

# Copyright (C) 2018-2019 Jonathan Roth, Benjamin Lim, Rishee K. Jain     
# This program is free software: you can redistribute it and/or modify it under the terms of the 
# GNU Affero General Public License as published by the Free Software Foundation, either version 
# 3 of the License, or (at your option) any later version.      
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; 
# without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  
# See the GNU Affero General Public License for more details. You should have received a copy of 
# the GNU Affero General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>.

library("stringr")
library("dplyr")

#READ IN DATA FOR MUNICIPAL AND COMMERCIAL BUILDINGS
minn_priv <- read.csv("/Users/benjaminlim/Desktop/City\ Benchmarking/MN/Minn_priv_2015.csv")
minn_pub <- read.csv("/Users/benjaminlim/Desktop/City\ Benchmarking/MN/Minn_pub_2015.csv")

minn_pub$Organization.Name <- NULL
minn_pub$Property.Name <- NULL

#rename columns in both public and private data
names(minn_pub) <- c("address", "zip", "energy_star_score", "property_type", "floor_area_building_SF", "floor_area_parking_SF", "year_built", "total_ghg_emission_MTCO2e", "site_eui_KBTUSF", "weather_norm_site_eui_KBTUSF", "source_eui_KBTUSF", "weather_norm_source_eui_KBTUSF", "water_use_KGAL")

names(minn_priv) <- c("address", "zip", "energy_star_score", "property_type", "floor_area_building_SF", "floor_area_parking_SF", "year_built", "total_ghg_emission_MTCO2e", "site_eui_KBTUSF", "weather_norm_site_eui_KBTUSF", "source_eui_KBTUSF", "weather_norm_source_eui_KBTUSF", "water_use_KGAL")

#join the two datasets by stacking them (same columns)
minn_joined = rbind(minn_priv,minn_pub)

#force datatypes
minn_joined$address=as.character(minn_joined$address)
minn_joined$zip=as.character(minn_joined$zip)
minn_joined$energy_star_score=as.numeric(minn_joined$energy_star_score)
minn_joined$property_type=as.character(minn_joined$property_type)
minn_joined$floor_area_building_SF=as.numeric(minn_joined$floor_area_building_SF)
minn_joined$floor_area_parking_SF=as.numeric(minn_joined$floor_area_parking_SF)
minn_joined$year_built=as.numeric(minn_joined$year_built)
minn_joined$total_ghg_emission_MTCO2e=as.numeric(minn_joined$total_ghg_emission_MTCO2e)
minn_joined$site_eui_KBTUSF=as.numeric(minn_joined$site_eui_KBTUSF)
minn_joined$weather_norm_site_eui_KBTUSF=as.numeric(minn_joined$weather_norm_site_eui_KBTUSF)
minn_joined$source_eui_KBTUSF=as.numeric(minn_joined$source_eui_KBTUSF)
minn_joined$weather_norm_source_eui_KBTUSF=as.numeric(minn_joined$weather_norm_source_eui_KBTUSF)
minn_joined$water_use_KGAL=as.numeric(minn_joined$water_use_KGAL)

#calculate total site energy (multiply only by building square footage, not parking)
minn_joined$total_site_energy_KBTU=minn_joined$site_eui_KBTUSF*minn_joined$floor_area_building_SF
minn_joined$log_total_site_energy_KBTU=log(minn_joined$total_site_energy_KBTU)

#remove outliers
MN_outliers_removed = minn_joined[minn_joined$site_eui_KBTUSF < (quantile(minn_joined$site_eui_KBTUSF, 0.75,na.rm=TRUE) + 4*IQR(minn_joined$site_eui_KBTUSF,na.rm=TRUE)),]
MN_outliers_removed = MN_outliers_removed[MN_outliers_removed$site_eui_KBTUSF > 1 ,]

#save cleaned data to csv file
write.csv(MN_outliers_removed, file = "MN_outliers_removed.csv")
```


```{r}
#reformat energy data addresses for MN
MN_outliers_removed$address_reform=paste(MN_outliers_removed$address,", MINNEAPOLIS, MN ",MN_outliers_removed$zip,sep="")
#this will be used to populate adr dataframe
write.csv(MN_outliers_removed$address_reform, "MN_addresses_energy.csv")

#reformat tax data addresses for MN
MN_tax <- read.csv("/Users/benjaminlim/Desktop/City\ Benchmarking/MN/AssessorsProperty.csv")
MN_tax$FORMATTED_ADDRESS=as.character(MN_tax$FORMATTED_ADDRESS)
MN_tax$ZIPCODE=as.character(MN_tax$ZIPCODE)
MN_tax$address_reform=paste(MN_tax$FORMATTED_ADDRESS,", MINNEAPOLIS, MN ",sep="")
#this will be used to populate adr dataframe
write.csv(MN_tax$address_reform, "MN_addresses_tax.csv")

```

```{r}
#column bind geocoded addresses back to energy data - prepping for merge
#adr is a temporary dataframe generated by the geocoding script
MN_energy_geocoded = cbind(MN_outliers_removed,adr)
write.csv(MN_energy_geocoded,"MN_energy_geocoded.csv")

#column bind geocoded addresses back to tax data - prepping for merge
#adr is a temporary dataframe generated by the geocoding script
MN_tax_geocoded = cbind(MN_tax,adr)
write.csv(MN_tax_geocoded,"MN_tax_geocoded.csv")

#left join for energy and tax data based on matching coordinates, keeping all energy data
library(plyr)
MN_merged <- join(MN_energy_geocoded, MN_tax_geocoded, by=c("lat","lon"), type="left", match="first")
write.csv(MN_merged,"MN_merged.csv")
```


```{r}
#remove all buildings that do not have site eui data
MN_merged_no_na=MN_merged[!is.na(MN_merged$site_eui_KBTUSF),]

#create file to delete extraneous columns in excel for ease
#write.csv(MN_merged_no_na, file="MN_impt_feats.csv")
```

```{r}
#read in file with extraneous columns removed
MN_impt_feats=read.csv("/Users/benjaminlim/Desktop/City\ Benchmarking/MN/MN_impt_feats.csv")

#delete columns where >40% of buildings have NA value
num_buildings=nrow(MN_impt_feats)
cols=ncol(MN_impt_feats)
keep_cols=rep(NA,cols)
removal_cols=rep(0,cols)
for (i in 1:cols){
keep_cols[i]=i
percent_na=nrow(MN_impt_feats[is.na(MN_impt_feats[,i]),])/num_buildings
  if (percent_na>0.40){
    removal_cols[i]=i
  }
}
keep_cols=keep_cols-removal_cols
keep_cols=keep_cols[keep_cols!=0]
removal_cols
MN_impt_feats_no_na=MN_impt_feats[,keep_cols]

#save file ready for imputation
write.csv(MN_impt_feats_no_na,"MN_rdy4imputation.csv")
sum(is.na(MN_impt_feats_no_na))
```

```{r}
#imputing values for NA on table without any energy data so as not to influence model results
impute=read.csv("/Users/benjaminlim/Desktop/City\ Benchmarking/impute/MN_rdy4imputation.csv")
mi = mice(impute,m=3,maxit=3,method='cart')
MN_imputed = complete(mi)
write.csv(MN_imputed,file="MN_imputed.csv")
#final dataset is created by adding all of the columns of relevant energy data to imputed data

```

